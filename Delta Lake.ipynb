{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de815f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from IPython.display import *\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07dcef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.85.95:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DeltaLakeApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x173ee456450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "            SparkSession\n",
    "                .builder\n",
    "                .appName(\"DeltaLakeApp\")\n",
    "    \n",
    "                .master(\"local[4]\")    \n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\")     \n",
    "    \n",
    "    \n",
    "                # Add package for Delta Lake\n",
    "                .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.0.0\")\n",
    "    \n",
    "    \n",
    "                # Add settings to use Delta Lake with Spark session\n",
    "                .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    \n",
    "                .config(\"spark.sql.catalog.spark_catalog\", \n",
    "                        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    \n",
    "                .getOrCreate()\n",
    "        )\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58003ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorId: integer (nullable = true)\n",
      " |-- PickupTime: timestamp (nullable = true)\n",
      " |-- DropTime: timestamp (nullable = true)\n",
      " |-- PassengerCount: double (nullable = true)\n",
      " |-- TripDistance: double (nullable = true)\n",
      " |-- RateCodeId: double (nullable = true)\n",
      " |-- StoreAndFwdFlag: string (nullable = true)\n",
      " |-- PickupLocationId: integer (nullable = true)\n",
      " |-- DropLocationId: integer (nullable = true)\n",
      " |-- PaymentType: integer (nullable = true)\n",
      " |-- FareAmount: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- MtaTax: double (nullable = true)\n",
      " |-- TipAmount: double (nullable = true)\n",
      " |-- TollsAmount: double (nullable = true)\n",
      " |-- ImprovementSurcharge: double (nullable = true)\n",
      " |-- TotalAmount: double (nullable = true)\n",
      " |-- CongestionSurcharge: double (nullable = true)\n",
      " |-- AirportFee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create schema for Yellow Taxi data\n",
    "yellowTaxiSchema = (\n",
    "                        StructType\n",
    "                        ([ \n",
    "                            StructField(\"VendorId\"               , IntegerType()   , True),\n",
    "                            StructField(\"PickupTime\"             , TimestampType() , True),\n",
    "                            StructField(\"DropTime\"               , TimestampType() , True),\n",
    "                            StructField(\"PassengerCount\"         , DoubleType()    , True),\n",
    "                            StructField(\"TripDistance\"           , DoubleType()    , True),\n",
    "                            StructField(\"RateCodeId\"             , DoubleType()    , True),\n",
    "                            StructField(\"StoreAndFwdFlag\"        , StringType()    , True),\n",
    "                            StructField(\"PickupLocationId\"       , IntegerType()   , True),\n",
    "                            StructField(\"DropLocationId\"         , IntegerType()   , True),\n",
    "                            StructField(\"PaymentType\"            , IntegerType()   , True),\n",
    "                            StructField(\"FareAmount\"             , DoubleType()    , True),\n",
    "                            StructField(\"Extra\"                  , DoubleType()    , True),\n",
    "                            StructField(\"MtaTax\"                 , DoubleType()    , True),\n",
    "                            StructField(\"TipAmount\"              , DoubleType()    , True),\n",
    "                            StructField(\"TollsAmount\"            , DoubleType()    , True),\n",
    "                            StructField(\"ImprovementSurcharge\"   , DoubleType()    , True),\n",
    "                            StructField(\"TotalAmount\"            , DoubleType()    , True),\n",
    "                            StructField(\"CongestionSurcharge\"    , DoubleType()    , True),\n",
    "                            StructField(\"AirportFee\"             , DoubleType()    , True)\n",
    "                        ])\n",
    "                   )\n",
    "\n",
    "\n",
    "# Read Yellow Taxis file\n",
    "yellowTaxiDF = (\n",
    "                  spark\n",
    "                    .read\n",
    "                    .option(\"header\", \"true\")    \n",
    "                    .schema(yellowTaxiSchema)    \n",
    "                    .csv(\"C:\\DataFiles\\YellowTaxis_202210.csv\")\n",
    "               )\n",
    "\n",
    "\n",
    "# Print schema of DataFrame\n",
    "yellowTaxiDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7ea16",
   "metadata": {},
   "source": [
    "### Create database in metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac588738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS TaxisDB\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e81385",
   "metadata": {},
   "source": [
    "### Parquet format: Save DataFrame as a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361f1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    yellowTaxiDF\n",
    "            .write    \n",
    "            .mode(\"overwrite\")\n",
    "    \n",
    "            .partitionBy(\"VendorId\")\n",
    "    \n",
    "            .format(\"parquet\")\n",
    "    \n",
    "            .option(\"path\", \"C:\\DataFiles\\Output\\YellowTaxis.parquet\")\n",
    "    \n",
    "            .saveAsTable(\"TaxisDB.YellowTaxisParquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1584bd",
   "metadata": {},
   "source": [
    "### Delta format: Save DataFrame as Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05749f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have already run this command, and want to start from beginning,\n",
    "# delete folder from file system first\n",
    "\n",
    "from delta import *\n",
    "\n",
    "(\n",
    "    yellowTaxiDF\n",
    "            .write    \n",
    "            .mode(\"overwrite\")\n",
    "    \n",
    "            .partitionBy(\"VendorId\")\n",
    "    \n",
    "            .format(\"delta\")\n",
    "    \n",
    "            .option(\"path\", \"C:\\DataFiles\\Output\\YellowTaxis.delta\")\n",
    "    \n",
    "            .saveAsTable(\"TaxisDB.YellowTaxis\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0dafe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 3675412|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63ea14",
   "metadata": {},
   "source": [
    "### Audit History of Delta Table\n",
    "\n",
    "This shows transaction log of Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca47c782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation                        |operationParameters                                                                     |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                     |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2024-01-08 15:29:25.073|NULL  |NULL    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> NULL, partitionBy -> [\"VendorId\"], properties -> {}}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 9, numOutputRows -> 3675412, numOutputBytes -> 80993013}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-08 15:26:50.195|NULL  |NULL    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> NULL, partitionBy -> [\"VendorId\"], properties -> {}}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 9, numOutputRows -> 3675412, numOutputBytes -> 80993013}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caff3a3",
   "metadata": {},
   "source": [
    "### Overwrite data in Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e86f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite data by re-running the command\n",
    "\n",
    "(\n",
    "    yellowTaxiDF\n",
    "            .write    \n",
    "            .mode(\"overwrite\")\n",
    "    \n",
    "            .partitionBy(\"VendorId\")\n",
    "    \n",
    "            .format(\"delta\")\n",
    "    \n",
    "            .option(\"path\", \"C:\\DataFiles\\Output\\YellowTaxis.delta\")\n",
    "    \n",
    "            .saveAsTable(\"TaxisDB.YellowTaxis\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820f4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation                        |operationParameters                                                                     |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                     |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|2      |2024-01-08 15:29:40.939|NULL  |NULL    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> NULL, partitionBy -> [\"VendorId\"], properties -> {}}|NULL|NULL    |NULL     |1          |Serializable  |false        |{numFiles -> 9, numOutputRows -> 3675412, numOutputBytes -> 80993013}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|1      |2024-01-08 15:29:25.073|NULL  |NULL    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> NULL, partitionBy -> [\"VendorId\"], properties -> {}}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 9, numOutputRows -> 3675412, numOutputBytes -> 80993013}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-08 15:26:50.195|NULL  |NULL    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> NULL, partitionBy -> [\"VendorId\"], properties -> {}}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 9, numOutputRows -> 3675412, numOutputBytes -> 80993013}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18d59fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DROP TABLE TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6100a3",
   "metadata": {},
   "source": [
    "### Create Table Definition\n",
    "\n",
    "Create table using DDL command, and later add the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebc9e9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE TaxisDB.YellowTaxis\n",
    "(\n",
    "    VendorId                INT               COMMENT 'Vendor providing the ride',\n",
    "    \n",
    "    PickupTime              TIMESTAMP,\n",
    "    DropTime                TIMESTAMP,\n",
    "    \n",
    "    PickupLocationId        INT               NOT NULL,\n",
    "    DropLocationId          INT,\n",
    "    \n",
    "    PassengerCount          DOUBLE,\n",
    "    TripDistance            DOUBLE,\n",
    "    \n",
    "    RateCodeId              DOUBLE,\n",
    "    StoreAndFwdFlag         STRING,\n",
    "    PaymentType             INT,\n",
    "    \n",
    "    FareAmount              DOUBLE,\n",
    "    Extra                   DOUBLE,\n",
    "    MtaTax                  DOUBLE,\n",
    "    TipAmount               DOUBLE,\n",
    "    TollsAmount             DOUBLE,\n",
    "    ImprovementSurcharge    DOUBLE,\n",
    "    TotalAmount             DOUBLE,\n",
    "    CongestionSurcharge     DOUBLE,\n",
    "    AirportFee              DOUBLE\n",
    ")\n",
    "\n",
    "USING DELTA                  -- default is Parquet\n",
    "\n",
    "LOCATION \"C:/SparkCourse/DataFiles/Output/YellowTaxis.delta/\"\n",
    "\n",
    "PARTITIONED BY (VendorId)    -- optional\n",
    "\n",
    "COMMENT 'This table stores ride information for Yellow Taxis'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e311bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------------------+-------------------------+\n",
      "|col_name                    |data_type                                              |comment                  |\n",
      "+----------------------------+-------------------------------------------------------+-------------------------+\n",
      "|VendorId                    |int                                                    |Vendor providing the ride|\n",
      "|PickupTime                  |timestamp                                              |NULL                     |\n",
      "|DropTime                    |timestamp                                              |NULL                     |\n",
      "|PickupLocationId            |int                                                    |NULL                     |\n",
      "|DropLocationId              |int                                                    |NULL                     |\n",
      "|PassengerCount              |double                                                 |NULL                     |\n",
      "|TripDistance                |double                                                 |NULL                     |\n",
      "|RateCodeId                  |double                                                 |NULL                     |\n",
      "|StoreAndFwdFlag             |string                                                 |NULL                     |\n",
      "|PaymentType                 |int                                                    |NULL                     |\n",
      "|FareAmount                  |double                                                 |NULL                     |\n",
      "|Extra                       |double                                                 |NULL                     |\n",
      "|MtaTax                      |double                                                 |NULL                     |\n",
      "|TipAmount                   |double                                                 |NULL                     |\n",
      "|TollsAmount                 |double                                                 |NULL                     |\n",
      "|ImprovementSurcharge        |double                                                 |NULL                     |\n",
      "|TotalAmount                 |double                                                 |NULL                     |\n",
      "|CongestionSurcharge         |double                                                 |NULL                     |\n",
      "|AirportFee                  |double                                                 |NULL                     |\n",
      "|# Partition Information     |                                                       |                         |\n",
      "|# col_name                  |data_type                                              |comment                  |\n",
      "|VendorId                    |int                                                    |Vendor providing the ride|\n",
      "|                            |                                                       |                         |\n",
      "|# Detailed Table Information|                                                       |                         |\n",
      "|Name                        |spark_catalog.taxisdb.yellowtaxis                      |                         |\n",
      "|Type                        |EXTERNAL                                               |                         |\n",
      "|Comment                     |This table stores ride information for Yellow Taxis    |                         |\n",
      "|Location                    |file:/C:/SparkCourse/DataFiles/Output/YellowTaxis.delta|                         |\n",
      "|Provider                    |delta                                                  |                         |\n",
      "|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]    |                         |\n",
      "+----------------------------+-------------------------------------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE TABLE EXTENDED TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb1329",
   "metadata": {},
   "source": [
    "### Options to Add Data to Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59dcfb5",
   "metadata": {},
   "source": [
    "#### Option 1: Insert command\n",
    "\n",
    "Use typical SQL Insert command to add data to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bab52cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "INSERT INTO TaxisDB.YellowTaxis\n",
    "\n",
    "-- (VendorId, PickupTime, DropTime, PickupLocationId, DropLocationId, PassengerCount, TripDistance, RateCodeId, StoreAndFwdFlag, PaymentType, FareAmount, Extra, MtaTax, TipAmount, TollsAmount, ImprovementSurcharge, TotalAmount, CongestionSurcharge, AirportFee)\n",
    "\n",
    "VALUES (3, '2022-12-01T00:00:00.000Z', '2022-12-01T00:15:34.000Z', 170, 140, 1.0, 2.9, 1.0, '1', 1, 13.0, 0.5, 0.5, 1.0, 0.0, 0.3, 15.3, 0.0, 0.0)\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3471e45b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+----------------+--------------+--------------+------------+----------+---------------+-----------+----------+-----+------+---------+-----------+--------------------+-----------+-------------------+----------+\n",
      "|VendorId|PickupTime         |DropTime           |PickupLocationId|DropLocationId|PassengerCount|TripDistance|RateCodeId|StoreAndFwdFlag|PaymentType|FareAmount|Extra|MtaTax|TipAmount|TollsAmount|ImprovementSurcharge|TotalAmount|CongestionSurcharge|AirportFee|\n",
      "+--------+-------------------+-------------------+----------------+--------------+--------------+------------+----------+---------------+-----------+----------+-----+------+---------+-----------+--------------------+-----------+-------------------+----------+\n",
      "|3       |2022-12-01 05:30:00|2022-12-01 05:45:34|170             |140           |1.0           |2.9         |1.0       |1              |1          |13.0      |0.5  |0.5   |1.0      |0.0        |0.3                 |15.3       |0.0                |0.0       |\n",
      "+--------+-------------------+-------------------+----------------+--------------+--------------+------------+----------+---------------+-----------+----------+-----+------+---------+-----------+--------------------+-----------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT * FROM TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f613a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+------------+---------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation   |operationParameters                                                                                                                    |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                           |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+------------+---------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2024-01-08 15:29:45.329|NULL  |NULL    |WRITE       |{mode -> Append, partitionBy -> []}                                                                                                    |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 5096}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-08 15:11:10.39 |NULL  |NULL    |CREATE TABLE|{isManaged -> false, description -> This table stores ride information for Yellow Taxis, partitionBy -> [\"VendorId\"], properties -> {}}|NULL|NULL    |NULL     |NULL       |Serializable  |true         |{}                                                         |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+------------+---------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4e950",
   "metadata": {},
   "source": [
    "#### Option 2: Append a DataFrame\n",
    "\n",
    "Read data as a DataFrame and append to Delta Table using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2393465",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/C:/SparkCourse/DataFiles/Raw/YellowTaxis_append.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract new records from Storage/Data Lake\u001b[39;00m\n\u001b[0;32m      3\u001b[0m yellowTaxisAppendDF \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      4\u001b[0m                           \u001b[43mspark\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43myellowTaxiSchema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSparkCourse\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDataFiles\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mRaw\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mYellowTaxis_append.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m                       )\n\u001b[0;32m     11\u001b[0m yellowTaxisAppendDF\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SparkEnvironment\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SparkEnvironment\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SparkEnvironment\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/C:/SparkCourse/DataFiles/Raw/YellowTaxis_append.csv."
     ]
    }
   ],
   "source": [
    "# Extract new records from Storage/Data Lake\n",
    "\n",
    "yellowTaxisAppendDF = (\n",
    "                          spark\n",
    "                            .read\n",
    "                            .option(\"header\", \"true\")\n",
    "                            .schema(yellowTaxiSchema)\n",
    "                            .csv(\"C:\\SparkCourse\\DataFiles\\Raw\\YellowTaxis_append.csv\")\n",
    "                      )\n",
    "\n",
    "yellowTaxisAppendDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to data lake in delta format\n",
    "\n",
    "(\n",
    "    yellowTaxisAppendDF\n",
    "        .write\n",
    "  \n",
    "        .mode(\"append\")\n",
    "  \n",
    "        .partitionBy(\"VendorId\")  \n",
    "        .format(\"delta\")           \n",
    "        .save(\"C:\\SparkCourse\\DataFiles\\Output\\YellowTaxis.delta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341ec8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT * \n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42471802",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to data lake in delta format\n",
    "(\n",
    "    yellowTaxiDF\n",
    "        .write\n",
    "  \n",
    "        .mode(\"append\")\n",
    "  \n",
    "        .partitionBy(\"VendorId\")  \n",
    "        .format(\"delta\")\n",
    "        .save(\"C:\\SparkCourse\\DataFiles\\Output\\YellowTaxis.delta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcad8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT COUNT(1)\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780fa4e",
   "metadata": {},
   "source": [
    "### Check files holding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT INPUT_FILE_NAME()\n",
    "     \n",
    "     , VendorId\n",
    "     , PickupLocationId\n",
    "     , PassengerCount\n",
    "     \n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b1a87",
   "metadata": {},
   "source": [
    "### UPDATE command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975cd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check passenger count\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT VendorId\n",
    "     , PickupLocationId\n",
    "     , PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 249\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdddd99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run update statement to change passenger count\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "UPDATE TaxisDB.YellowTaxis\n",
    "\n",
    "SET PassengerCount = 2\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 249\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check passenger count after update\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT VendorId\n",
    "     , PickupLocationId\n",
    "     , PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 249\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c696d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37baa2d3",
   "metadata": {},
   "source": [
    "### DELETE command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5b0f277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------+\n",
      "|VendorId|PickupLocationId|PassengerCount|\n",
      "+--------+----------------+--------------+\n",
      "+--------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if record exist\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT VendorId\n",
    "     , PickupLocationId\n",
    "     , PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 151\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb297ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|                0|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete the record\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "DELETE FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 151\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc510da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if record exist after delete operation\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT VendorId\n",
    "     , PickupLocationId\n",
    "     , PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 151\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44901e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bb621",
   "metadata": {},
   "source": [
    "### MERGE command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ea04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract changed records from Storage/Data Lake\n",
    "\n",
    "yellowTaxiChangesDF = (\n",
    "                          spark\n",
    "                            .read\n",
    "                            .option(\"header\", \"true\")\n",
    "                            .schema(yellowTaxiSchema)\n",
    "                            .csv(\"C:\\SparkCourse\\DataFiles\\Raw\\YellowTaxis_changes.csv\")\n",
    "                      )\n",
    "\n",
    "yellowTaxiChangesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellowTaxiChangesDF.createOrReplaceTempView(\"YellowTaxiChanges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58137217",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT *\n",
    "FROM YellowTaxiChanges\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "MERGE INTO TaxisDB.YellowTaxis tgt\n",
    "\n",
    "    USING YellowTaxiChanges    src\n",
    "\n",
    "        ON    tgt.VendorId          =  src.VendorId\n",
    "          AND tgt.PickupLocationId  =  src.PickupLocationId\n",
    "  \n",
    "-- Update row if join conditions match\n",
    "WHEN MATCHED\n",
    "      \n",
    "      THEN  \n",
    "          UPDATE SET    tgt.PaymentType = src.PaymentType   \n",
    "          \n",
    "                                                      -- Use 'UPDATE SET *' to update all columns\n",
    "\n",
    "-- Insert row if row is not present in target table\n",
    "WHEN NOT MATCHED \n",
    "      AND PickupTime >= '2022-03-01'\n",
    "\n",
    "      THEN \n",
    "          INSERT (VendorId, PickupTime, DropTime, PickupLocationId, DropLocationId, PassengerCount, TripDistance, \n",
    "                  RateCodeId, StoreAndFwdFlag, PaymentType, FareAmount, Extra, MtaTax, TipAmount, TollsAmount, \n",
    "                  ImprovementSurcharge, TotalAmount, CongestionSurcharge, AirportFee)\n",
    "          \n",
    "          VALUES (VendorId, PickupTime, DropTime, PickupLocationId, DropLocationId, PassengerCount, TripDistance,\n",
    "                  RateCodeId, StoreAndFwdFlag, PaymentType, FareAmount, Extra, MtaTax, TipAmount, TollsAmount, \n",
    "                  ImprovementSurcharge, TotalAmount, CongestionSurcharge, AirportFee)\n",
    "                                                                         \n",
    "\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9130c3a",
   "metadata": {},
   "source": [
    "### Constraints on Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46f18e",
   "metadata": {},
   "source": [
    "#### NOT NULL constraint\n",
    "\n",
    "Drop the constraint here which was previously created\n",
    "\n",
    "<i>- Define NOT NULL constraint on column to avoid insertion of NULL values </i> <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca78a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "ALTER TABLE TaxisDB.YellowTaxis\n",
    "\n",
    "      CHANGE COLUMN PickupLocationId DROP NOT NULL\n",
    "\n",
    "\"\"\").show()\n",
    "\n",
    "\n",
    "# At the time of recording, Open Issue: https://github.com/delta-io/delta/issues/831\n",
    "# Does not allow to set column as null after table creation\n",
    "\n",
    "# ALTER TABLE TaxisDB.YellowTaxis\n",
    "#      CHANGE COLUMN PickupLocationId SET NOT NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540621b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41a2fd",
   "metadata": {},
   "source": [
    "#### CHECK constraint\n",
    "\n",
    "Check constraint helps to enforce certain conditions on the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5332b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "ALTER TABLE TaxisDB.YellowTaxis\n",
    "\n",
    "    ADD CONSTRAINT PassengerCountCheck CHECK (PassengerCount <= 5)\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "ALTER TABLE TaxisDB.YellowTaxis\n",
    "\n",
    "    ADD CONSTRAINT PassengerCheck CHECK (PassengerCount <= 9 OR PassengerCount IS NULL)\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f496f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "INSERT INTO TaxisDB.YellowTaxis\n",
    "\n",
    "--(VendorId, PickupTime, DropTime, PickupLocationId, \n",
    "DropLocationId, PassengerCount, TripDistance, RateCodeId, \n",
    "StoreAndFwdFlag, PaymentType, FareAmount, Extra, MtaTax, TipAmount, \n",
    "TollsAmount, ImprovementSurcharge, TotalAmount, CongestionSurcharge, AirportFee)\n",
    "\n",
    "VALUES (3, '2022-12-01T00:00:00.000Z', '2022-12-01T00:15:34.000Z', 170, 140, \n",
    "\n",
    "        20,  -- PassengerCount\n",
    "\n",
    "        2.9, 1.0, '1', 1, 13.0, 0.5, 0.5, 1.0, 0.0, 0.3, 15.3, 0.0, 0.0)\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a6de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "ALTER TABLE TaxisDB.YellowTaxis\n",
    "\n",
    "    DROP CONSTRAINT PassengerCheck\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16431ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac57f5",
   "metadata": {},
   "source": [
    "### Update a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check passenger count before update\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 1\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update passenger count\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "UPDATE TaxisDB.YellowTaxis\n",
    "\n",
    "SET PassengerCount = 1\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 1\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fb04c",
   "metadata": {},
   "source": [
    "### Time Travel: Access using Version Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check at initial version\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis        VERSION AS OF 0\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 1\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check at one prior version\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis        VERSION AS OF 9\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 1\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda55aa4",
   "metadata": {},
   "source": [
    "### Time Travel: Access using Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f970a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis        TIMESTAMP AS OF '2023-03-12 22:39:00'\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 1\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0d7d3",
   "metadata": {},
   "source": [
    "### Restore Table to older version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137c072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "RESTORE TABLE TaxisDB.YellowTaxis    TO VERSION AS OF 9\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d086fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data after restore\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT PassengerCount\n",
    "\n",
    "FROM TaxisDB.YellowTaxis\n",
    "\n",
    "WHERE VendorId = 3\n",
    "    AND PickupLocationId = 1\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86106a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeabe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b356cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229769e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b911317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f67430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c813c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d631c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ab284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a91ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338d50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d6b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973a295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
